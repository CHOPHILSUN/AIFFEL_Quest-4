{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247b2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "def one_hot_encoding(data, dim=10000): # 아래 imdb.load_data의 num_words를 10000으로 설정할 예정이기 때문에 dim도 10000으로 맞춰줍니다.\n",
    "  results = np.zeros((len(data), dim))\n",
    "  for i, d in enumerate(data):\n",
    "    results[i, d] = 1.\n",
    "  return results\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "x_train = one_hot_encoding(train_data)\n",
    "x_test = one_hot_encoding(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971c349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 128)               1280128   \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,296,769\n",
      "Trainable params: 1,296,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(10000, ), name='input'))\n",
    "model.add(layers.Dense(128, activation='relu', name='hidden'))\n",
    "model.add(layers.Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc110270",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca349b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r--', label='val_loss')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, accuracy, 'b--', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r--', label='val_accuracy')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1599b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_model = models.Sequential()\n",
    "b_model.add(layers.Dense(2048, activation='relu', input_shape=(10000, ), name='input3'))\n",
    "b_model.add(layers.Dense(2048, activation='relu', name='hidden3'))\n",
    "b_model.add(layers.Dense(1, activation='sigmoid', name='output3'))\n",
    "b_model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "b_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_model_history = b_model.fit(x_train, y_train,\n",
    "                              epochs=30,\n",
    "                              batch_size=512, \n",
    "                              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6fd65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_history_dict = b_model_history.history\n",
    "\n",
    "b_loss = b_history_dict['loss']\n",
    "b_val_loss = b_history_dict['val_loss']\n",
    "epochs = range(1, len(b_loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, b_loss, 'b-', label='train_loss(large)')\n",
    "ax1.plot(epochs, b_val_loss, 'r-', label='val_loss(large)')\n",
    "ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r--', label='val_loss')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "b_accuracy = b_history_dict['accuracy']\n",
    "b_val_accuracy = b_history_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, b_accuracy, 'b-', label='train_accuracy(large)')\n",
    "ax2.plot(epochs, b_val_accuracy, 'r-', label='val_accuracy(large)')\n",
    "ax2.plot(epochs, accuracy, 'b--', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r--', label='val_accuracy')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model = models.Sequential()\n",
    "s_model.add(layers.Dense(16, activation='relu', input_shape=(10000, ), name='input2'))\n",
    "s_model.add(layers.Dense(16, activation='relu', name='hidden2'))\n",
    "s_model.add(layers.Dense(1, activation='sigmoid', name='output2'))\n",
    "s_model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model_history = s_model.fit(x_train, y_train,\n",
    "                              epochs=30,\n",
    "                              batch_size=512, \n",
    "                              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5be0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_history_dict = s_model_history.history\n",
    "\n",
    "s_loss = s_history_dict['loss']\n",
    "s_val_loss = s_history_dict['val_loss']\n",
    "epochs = range(1, len(s_loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, b_loss, 'b-', label='train_loss(large)')\n",
    "ax1.plot(epochs, b_val_loss, 'r-', label='val_loss(large)')\n",
    "ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r--', label='val_loss')\n",
    "ax1.plot(epochs, s_loss, 'b:', label='train_loss(small)')\n",
    "ax1.plot(epochs, s_val_loss, 'r:', label='val_loss(small)')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "s_accuracy = s_history_dict['accuracy']\n",
    "s_val_accuracy = s_history_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, b_accuracy, 'b-', label='train_accuracy(large)')\n",
    "ax2.plot(epochs, b_val_accuracy, 'r-', label='val_accuracy(large)')\n",
    "ax2.plot(epochs, accuracy, 'b--', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r--', label='val_accuracy')\n",
    "ax2.plot(epochs, s_accuracy, 'b:', label='train_accuracy(small)')\n",
    "ax2.plot(epochs, s_val_accuracy, 'r:', label='val_accuracy(small)')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25961c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [play ground]\n",
    "# 원하는 분은 Dense층을 늘리거나 줄이는 등 모델의 구조 역시 변경해보시기 바랍니다.\n",
    "\n",
    "your_model = models.Sequential()\n",
    "your_model.add(layers.Dense(512, activation='relu', input_shape=(10000, ), name='input2'))\n",
    "your_model.add(layers.Dense(512, activation='relu', name='hidden2'))\n",
    "your_model.add(layers.Dense(1, activation='sigmoid', name='output2'))\n",
    "your_model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "your_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model_history = your_model.fit(x_train, y_train, epochs=30, batch_size=512,  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516feb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_history_dict = your_model_history.history\n",
    "\n",
    "your_loss = your_history_dict['loss']\n",
    "your_val_loss = your_history_dict['val_loss']\n",
    "epochs = range(1, len(your_loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, b_loss, 'b-', label='train_loss(large)')\n",
    "ax1.plot(epochs, b_val_loss, 'r-', label='val_loss(large)')\n",
    "ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r--', label='val_loss')\n",
    "ax1.plot(epochs, your_loss, 'b:', label='train_loss(small)')\n",
    "ax1.plot(epochs, your_val_loss, 'r:', label='val_loss(small)')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "your_accuracy = your_history_dict['accuracy']\n",
    "your_val_accuracy = your_history_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, b_accuracy, 'b-', label='train_accuracy(large)')\n",
    "ax2.plot(epochs, b_val_accuracy, 'r-', label='val_accuracy(large)')\n",
    "ax2.plot(epochs, accuracy, 'b--', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r--', label='val_accuracy')\n",
    "ax2.plot(epochs, s_accuracy, 'b:', label='train_accuracy(small)')\n",
    "ax2.plot(epochs, s_val_accuracy, 'r:', label='val_accuracy(small)')\n",
    "ax2.plot(epochs, your_accuracy, 'g-', label='train_accuracy(your)')\n",
    "ax2.plot(epochs, your_val_accuracy, 'g--', label='val_accuracy(your)')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model =  models.Sequential()\n",
    "l1_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer='l1',\n",
    "                          activation='relu', \n",
    "                          input_shape=(10000, )))\n",
    "l1_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer='l1',\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "l1_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "l1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0429b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model_hist = l1_model.fit(x_train, y_train,\n",
    "                             epochs=30,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_val_loss = l1_model_hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, 31)\n",
    "plt.plot(epochs, val_loss, 'k--', label='Model')\n",
    "plt.plot(epochs, l1_val_loss, 'b--', label='L1-regularized')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c247f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model =  models.Sequential()\n",
    "l2_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer='l2',\n",
    "                          activation='relu', \n",
    "                          input_shape=(10000, )))\n",
    "l2_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer='l2',\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "l2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=30,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c58deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, 31)\n",
    "plt.plot(epochs, val_loss, 'k--', label='Model')\n",
    "plt.plot(epochs, l2_val_loss, 'r--', label='L2-regularized')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb59740",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_l2_model =  models.Sequential()\n",
    "l1_l2_model.add(layers.Dense(16, \n",
    "                             kernel_regularizer='l1_l2',\n",
    "                             activation='relu', input_shape=(10000, )))\n",
    "l1_l2_model.add(layers.Dense(16, \n",
    "                             kernel_regularizer='l1_l2',\n",
    "                             activation='relu'))\n",
    "l1_l2_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "l1_l2_model.compile(optimizer='rmsprop',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "l1_l2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_l2_model_hist = l1_l2_model.fit(x_train, y_train,\n",
    "                                  epochs=30,\n",
    "                                  batch_size=512,\n",
    "                                  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e732e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_l2_val_loss = l1_l2_model_hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, 31)\n",
    "plt.plot(epochs, val_loss, 'k--', label='Model')\n",
    "plt.plot(epochs, l1_l2_val_loss, 'g--', label='L1_L2-regularized')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df04ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 31)\n",
    "plt.plot(epochs, val_loss, 'k--', label='Model')\n",
    "plt.plot(epochs, l1_val_loss, 'b--', label='L1-regularized')\n",
    "plt.plot(epochs, l2_val_loss, 'r--', label='L2-regularized')\n",
    "plt.plot(epochs, l1_l2_val_loss, 'g--', label='L1_L2-regularized')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa30e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [play ground]\n",
    "# L2 규제의 기본 값은 0.01입니다. 여러분이 원하는 크기로 조절해보세요. 혹은 다른 규제를 사용하셔도 됩니다.\n",
    "import keras\n",
    "\n",
    "your_model =  models.Sequential()\n",
    "your_model.add(layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.005), activation='relu', input_shape=(10000, )))\n",
    "your_model.add(layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.015), activation='relu'))\n",
    "your_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "your_model.compile(optimizer='rmsprop',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "your_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model_hist = your_model.fit(x_train, y_train,\n",
    "                                 epochs=30,\n",
    "                                 batch_size=512,\n",
    "                                 validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678fbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_val_loss = your_model_hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, 31)\n",
    "plt.plot(epochs, val_loss, 'k--', label='Model')\n",
    "plt.plot(epochs, l1_val_loss, 'b--', label='L1-regularized')\n",
    "plt.plot(epochs, l2_val_loss, 'r--', label='L2-regularized')\n",
    "plt.plot(epochs, l1_l2_val_loss, 'g--', label='L1_L2-regularized')\n",
    "plt.plot(epochs, your_val_loss, 'y--', label='Your L2-regularized')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000, )))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_20_history = model.fit(x_train, y_train,\n",
    "                            epochs=30,\n",
    "                            batch_size=512,\n",
    "                            validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_20_dict = drop_20_history.history\n",
    "\n",
    "drop_20_loss = drop_20_dict['loss']\n",
    "drop_20_val_loss = drop_20_dict['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, loss, 'b-', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r-', label='val_loss')\n",
    "ax1.plot(epochs, drop_20_loss, 'b--', label='train_loss (dropout 20%)')\n",
    "ax1.plot(epochs, drop_20_val_loss, 'r--', label='val_loss (dropout 20%)')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "drop_20_accuracy = drop_20_dict['accuracy']\n",
    "drop_20_val_accuracy = drop_20_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, accuracy, 'b-', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r-', label='val_accuracy')\n",
    "ax2.plot(epochs, drop_20_accuracy, 'b--', label='train_accuracy (dropout 20%)')\n",
    "ax2.plot(epochs, drop_20_val_accuracy, 'r--', label='val_accuracy (dropout 20%)')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000, )))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c806b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_50_history = model.fit(x_train, y_train,\n",
    "                            epochs=30,\n",
    "                            batch_size=512,\n",
    "                            validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0470046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_50_dict = drop_50_history.history\n",
    "\n",
    "drop_50_loss = drop_50_dict['loss']\n",
    "drop_50_val_loss = drop_50_dict['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, loss, 'b-', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r-', label='val_loss')\n",
    "ax1.plot(epochs, drop_20_loss, 'b--', label='train_loss (dropout 20%)')\n",
    "ax1.plot(epochs, drop_20_val_loss, 'r--', label='val_loss (dropout 20%)')\n",
    "ax1.plot(epochs, drop_50_loss, 'b:', label='train_loss (dropout 50%)')\n",
    "ax1.plot(epochs, drop_50_val_loss, 'r:', label='val_loss (dropout 50%)')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "drop_50_accuracy = drop_50_dict['accuracy']\n",
    "drop_50_val_accuracy = drop_50_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, accuracy, 'b-', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r-', label='val_accuracy')\n",
    "ax2.plot(epochs, drop_20_accuracy, 'b--', label='train_accuracy (dropout 20%)')\n",
    "ax2.plot(epochs, drop_20_val_accuracy, 'r--', label='val_accuracy (dropout 20%)')\n",
    "ax2.plot(epochs, drop_50_accuracy, 'b:', label='train_accuracy (dropout 50%)')\n",
    "ax2.plot(epochs, drop_50_val_accuracy, 'r:', label='val_accuracy (dropout 50%)')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
